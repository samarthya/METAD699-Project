{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD699 Semester Project: Zurich Airbnb Data Analysis\n",
    "## Team: Group 5\n",
    "## Members: Yixuan Yang, Gavin Boss, Eva Sanchez, Saurabh Sharma\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "This project analyzes Airbnb rental data from Zurich, Switzerland to uncover patterns in pricing, amenities, host behavior, and geographic clustering. We employ various data mining techniques including regression, classification (k-NN, decision trees, transformers), and clustering to extract insights from real-world rental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For text processing and word clouds\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "# For mapping\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix, mean_absolute_error\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For transformers (we'll use a simple approach with sentence transformers)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  pandas version: {pd.__version__}\")\n",
    "print(f\"  numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created '{output_dir}' directory\")\n",
    "else:\n",
    "    print(f\"'{output_dir}' directory already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Data Preparation & Exploration\n",
    "\n",
    "## 1.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Zurich Airbnb dataset\n",
    "df = pd.read_csv('data/zurich_listings.csv')\n",
    "\n",
    "rows, columns = df.shape\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset Shape: {rows} rows × {columns} columns\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSample rows\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Missing Values Analysis and Treatment\n",
    "\n",
    "### Understanding the Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values for each column\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "# Show only columns with missing values\n",
    "missing_data_filtered = missing_data[missing_data['Missing_Count'] > 0]\n",
    "print(f\"Columns with missing values: {len(missing_data_filtered)}\\n\")\n",
    "print(missing_data_filtered.head(20))\n",
    "\n",
    "# Visualize missing data patterns\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_missing = missing_data_filtered.head(15)\n",
    "plt.barh(top_missing['Column'], top_missing['Missing_Percentage'])\n",
    "plt.xlabel('Percentage Missing (%)')\n",
    "plt.title('Top 15 Columns with Missing Values')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/missing_values_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Treatment Strategy\n",
    "\n",
    "**Our Approach to Handling Missing Values:**\n",
    "\n",
    "After analyzing the missing data patterns in our Zurich Airbnb dataset, we developed a strategic approach to handle missing values based on the nature of each variable and its importance for our analyses:\n",
    "\n",
    "**1. Text Fields (`description`, `neighborhood_overview`, `host_about`):** For text columns with missing values, we replace NaN with empty strings. This is crucial for our transformer model in the classification section, as missing text data __doesn't necessarily indicate lack of information—some hosts simply don't provide certain descriptions__. By converting to empty strings, we can still process these records through text analysis without losing valuable data points.\n",
    "\n",
    "**2. Review Scores and Metrics:** Columns like `review_scores_rating`, `review_scores_cleanliness`, and `reviews_per_month` have missing values primarily because some listings haven't received reviews yet. For regression analysis, we'll either exclude these rows or use median imputation depending on the specific model. For listings without reviews, this is legitimate missing data rather than a data quality issue—new listings naturally lack review history.\n",
    "\n",
    "**3. Numerical Features (`bedrooms`, `beds`):** We use __median imputation__ for missing numerical features. The median is more robust to outliers than the mean, which is important for rental data where luxury properties can skew averages. For example, if bedrooms are missing, we impute the median number of bedrooms for similar property types.\n",
    "\n",
    "**4. Bathrooms Handling:** The original `bathrooms` column is 100% missing (Airbnb deprecated this numeric field). However, the `bathrooms_text` column contains descriptive information like \"1.5 baths\" or \"2 shared baths\". We extract the numeric value using regex pattern matching, then apply median imputation to any remaining missing values. This creates a clean `bathrooms_clean` variable suitable for quantitative analysis.\n",
    "\n",
    "**5. Price Variable:** Since `price` is our key outcome variable for regression, we'll remove any rows where price is missing. These represent only a small fraction of our data, and imputing the target variable would compromise our model's integrity. This ensures our predictions are based on actual market prices.\n",
    "\n",
    "**6. Host Response Information:** For `host_response_time` and `host_response_rate`, missing values often indicate hosts who haven't yet established a response pattern. We'll handle these carefully in our classification tree analysis, potentially creating a separate \"Unknown\" category to preserve these data points.\n",
    "\n",
    "This multi-faceted approach balances data retention with analytical validity. We avoid simply dropping all rows with any missing values (which would eliminate over 50% of our dataset) while ensuring that our imputation methods don't introduce bias into our models. Different analyses may warrant different treatments, and we'll adapt our strategy as needed for each section of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy of the dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Handle price column - convert from string to numeric\n",
    "# Price is stored as '$XXX.XX' format, need to clean it\n",
    "def clean_price(price):\n",
    "    \"\"\"Convert price from string format to numeric\"\"\"\n",
    "    if pd.isna(price):\n",
    "        return np.nan\n",
    "    # Remove '$' and ',' from price string\n",
    "    return float(str(price).replace('$', '').replace(',', ''))\n",
    "\n",
    "df_clean['price'] = df_clean['price'].apply(clean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Handle bathrooms_text column - extract numeric bathroom count\n",
    "def extract_bathrooms(bath_text):\n",
    "    \"\"\"\n",
    "    Extract numeric bathroom count from descriptive text.\n",
    "    E.g: '1.5 baths' → 1.5, '2 shared baths' → 2.0\n",
    "    \"\"\"\n",
    "    if pd.isna(bath_text) or bath_text == '':\n",
    "        return np.nan\n",
    "    # Use regex to find first number\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', str(bath_text))\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "df_clean['bathrooms_clean'] = df_clean['bathrooms_text'].apply(extract_bathrooms)\n",
    "bathrooms_median = df_clean['bathrooms_clean'].median()\n",
    "df_clean['bathrooms_clean'] = df_clean['bathrooms_clean'].fillna(bathrooms_median)\n",
    "print(f\"Extracted and filled bathrooms. Median: {bathrooms_median}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Fill text columns with empty strings\n",
    "text_columns = ['description', 'neighborhood_overview', 'host_about', 'name']\n",
    "for col in text_columns:\n",
    "    df_clean[col] = df_clean[col].fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle numerical features with median imputation\n",
    "numeric_features = ['bedrooms', 'beds']  # bathrooms handled separately above\n",
    "for col in numeric_features:\n",
    "    if col in df_clean.columns:\n",
    "        median_val = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_val)\n",
    "        print(f\"Filled {col} missing values with median: {median_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Handle host_response_time - create 'unknown' category\n",
    "if 'host_response_time' in df_clean.columns:\n",
    "    df_clean['host_response_time'] = df_clean['host_response_time'].fillna('unknown')\n",
    "\n",
    "# 6. Fill review scores with median (alternative: could drop these rows for specific analyses)\n",
    "review_columns = ['review_scores_rating', \n",
    "                  'review_scores_accuracy', \n",
    "                  'review_scores_cleanliness', \n",
    "                  'review_scores_checkin',\n",
    "                  'review_scores_communication', \n",
    "                  'review_scores_location', \n",
    "                  'review_scores_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in review_columns:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "# 7. Fill reviews_per_month with 0 (no reviews means 0 reviews per month)\n",
    "df_clean['reviews_per_month'] = df_clean['reviews_per_month'].fillna(0)\n",
    "\n",
    "print(\"\\nMissing Values After Treatment\")\n",
    "\n",
    "print(f\"Rows remaining: {len(df_clean)}\")\n",
    "print(f\"\\nColumns with missing values: {df_clean.isnull().sum().sum()}\")\n",
    "print(\"\\nTop columns still with missing values:\")\n",
    "still_missing = df_clean.isnull().sum().sort_values(ascending=False).head(10)\n",
    "print(still_missing[still_missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Summary Statistics by Neighborhood\n",
    "\n",
    "### Exploring Geographic Variations in Zurich Rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's see what neighborhoods we have\n",
    "print(\"Number of unique neighborhoods:\", df_clean['neighbourhood_cleansed'].nunique())\n",
    "print(\"\\nTop 10 neighborhoods by listing count:\")\n",
    "neighborhood_counts = df_clean['neighbourhood_cleansed'].value_counts().head(10)\n",
    "print(neighborhood_counts)\n",
    "\n",
    "# Focus on top 10 neighborhoods for clearer analysis\n",
    "top_neighborhoods = neighborhood_counts.index.tolist()\n",
    "df_top_neighborhoods = df_clean[df_clean['neighbourhood_cleansed'].isin(top_neighborhoods)]\n",
    "\n",
    "print(f\"\\nAnalyzing {len(df_top_neighborhoods)} listings across {len(top_neighborhoods)} neighborhoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistic 1: Average Price by Neighborhood\n",
    "print(\"SUMMARY STATISTIC 1: Average Price by Neighborhood\")\n",
    "\n",
    "price_by_neighborhood = df_top_neighborhoods.groupby('neighbourhood_cleansed')['price'].agg([\n",
    "    ('Mean Price (CHF)', 'mean'),\n",
    "    ('Median Price (CHF)', 'median'),\n",
    "    ('Std Dev', 'std'),\n",
    "    ('Count', 'count')\n",
    "]).round(2).sort_values('Mean Price (CHF)', ascending=False)\n",
    "\n",
    "print(price_by_neighborhood)\n",
    "\n",
    "print(\"\\nTakeaway: This shows which neighborhoods command premium prices. \")\n",
    "print(\"High standard deviation indicates diverse property types within a neighborhood.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistic 2: Property Type Distribution by Neighborhood\n",
    "print(\"SUMMARY STATISTIC 2: Room Type Distribution by Neighborhood\")\n",
    "\n",
    "\n",
    "room_type_dist = pd.crosstab(\n",
    "    df_top_neighborhoods['neighbourhood_cleansed'], \n",
    "    df_top_neighborhoods['room_type'], \n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(room_type_dist.round(2))\n",
    "\n",
    "print(\"\\nTakeaway: This reveals whether neighborhoods cater to different traveler types.\")\n",
    "\n",
    "# TBD add more details?\n",
    "# Kind of straight forward deduction\n",
    "print(\"High 'Entire home/apt' % suggests family-oriented areas; high 'Private room' suggests budget options.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistic 3: Average Review Scores by Neighborhood\n",
    "print(\"SUMMARY STATISTIC 3: Average Review Scores by Neighborhood\")\n",
    "\n",
    "review_by_neighborhood = df_top_neighborhoods.groupby('neighbourhood_cleansed').agg({\n",
    "    'review_scores_rating': 'mean',\n",
    "    'review_scores_location': 'mean',\n",
    "    'review_scores_value': 'mean',\n",
    "    'number_of_reviews': 'mean'\n",
    "}).round(2).sort_values('review_scores_rating', ascending=False)\n",
    "\n",
    "review_by_neighborhood.columns = ['Overall Rating', 'Location Score', 'Value Score', 'Avg # Reviews']\n",
    "print(review_by_neighborhood)\n",
    "\n",
    "print(\"\\nTakeaway: Higher location scores indicate desirable areas for tourists.\")\n",
    "print(\"Discrepancies between overall rating and value suggest price sensitivity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistic 4: Accommodation Capacity by Neighborhood\n",
    "print(\"SUMMARY STATISTIC 4: Property Size Metrics by Neighborhood\")\n",
    "\n",
    "capacity_by_neighborhood = df_top_neighborhoods.groupby('neighbourhood_cleansed').agg({\n",
    "    'accommodates': 'mean',\n",
    "    'bedrooms': 'mean',\n",
    "    'beds': 'mean',\n",
    "    'bathrooms_clean': 'mean'\n",
    "}).round(2).sort_values('accommodates', ascending=False)\n",
    "\n",
    "capacity_by_neighborhood.columns = ['Avg Guests', 'Avg Bedrooms', 'Avg Beds', 'Avg Bathrooms']\n",
    "\n",
    "print(capacity_by_neighborhood)\n",
    "\n",
    "print(\"\\nTakeaway: Neighborhoods with larger properties may cater to families or groups.\")\n",
    "print(\"This metric helps understand the target demographic for each area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistic 5: Host Response Metrics by Neighborhood\n",
    "print(\"SUMMARY STATISTIC 5: Host Professionalism by Neighborhood\")\n",
    "\n",
    "# Clean host_response_rate (convert percentage string to float)\n",
    "def clean_percentage(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    return float(str(val).replace('%', ''))\n",
    "\n",
    "df_top_neighborhoods['host_response_rate_clean'] = df_top_neighborhoods['host_response_rate'].apply(clean_percentage)\n",
    "\n",
    "host_metrics = df_top_neighborhoods.groupby('neighbourhood_cleansed').agg({\n",
    "    'host_response_rate_clean': 'mean',\n",
    "    'host_is_superhost': lambda x: (x == 't').sum() / len(x) * 100,\n",
    "    'instant_bookable': lambda x: (x == 't').sum() / len(x) * 100,\n",
    "    'host_total_listings_count': 'mean'\n",
    "}).round(2).sort_values('host_response_rate_clean', ascending=False)\n",
    "\n",
    "host_metrics.columns = ['Response Rate %', 'Superhost %', 'Instant Book %', 'Avg Listings per Host']\n",
    "\n",
    "print(host_metrics)\n",
    "\n",
    "print(\"\\nTakeaway: High superhost % and response rates indicate professional hosting culture.\")\n",
    "print(\"Multiple listings per host may indicate commercial operations vs. individual hosts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics Findings\n",
    "\n",
    "Our analysis of Zurich's top __neighborhoods__ reveals distinct patterns in the short-term rental market:\n",
    "\n",
    "**Pricing Patterns:** The neighborhoods show considerable variation in average prices, reflecting Zurich's diverse urban geography. Central districts and areas near major attractions command premium prices, while peripheral neighborhoods offer more budget-friendly options. The standard deviation in prices within neighborhoods indicates that even \"expensive\" areas have affordable options, likely reflecting the mix of property types (entire apartments vs. private rooms).\n",
    "\n",
    "**Property Type Distribution:** The room type distribution shows which neighborhoods cater to different traveler segments. Areas with high percentages of entire homes/apartments typically serve families and longer-term visitors, while neighborhoods dominated by private rooms attract budget-conscious solo travelers and backpackers. This segmentation helps property owners understand their competition and helps travelers find suitable neighborhoods.\n",
    "\n",
    "**Guest Experience:** Review scores provide insight into guest satisfaction across neighborhoods. Interestingly, location scores often vary independently from overall ratings, suggesting that some areas sacrifice convenience for value or space. The average number of reviews per neighborhood indicates booking velocity—neighborhoods with higher review counts see more turnover, suggesting either high demand or shorter average stays.\n",
    "\n",
    "**Property Characteristics:** The accommodation capacity metrics reveal the typical property profile in each neighborhood. Areas with higher average guest capacity and bedroom counts likely contain more family-oriented rentals, while lower capacity suggests studio apartments and rooms for business travelers. This information is valuable for understanding inventory composition.\n",
    "\n",
    "**Host Professionalism:** The host metrics illuminate the operational character of each neighborhood's rental market. Areas with high superhost percentages and response rates indicate a mature, professional hosting ecosystem. Higher listings-per-host averages suggest the presence of property management companies or commercial operators, while lower numbers indicate more individual, owner-occupied rentals. This distinction affects guest experience and market dynamics—commercial operations may offer more consistency but less personal touches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data Visualizations\n",
    "\n",
    "### Five Different Visualization Types to Understand Zurich's Rental Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Box Plot - Price Distribution Across Top Neighborhoods\n",
    "plt.figure(figsize=(14, 6))\n",
    "# Filter extreme outliers for better visualization\n",
    "price_data = df_top_neighborhoods[df_top_neighborhoods['price'] <= df_top_neighborhoods['price'].quantile(0.95)]\n",
    "\n",
    "sns.boxplot(data=price_data, x='neighbourhood_cleansed', y='price')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Price Distribution Across Top Zurich Neighborhoods\\n(95th percentile capped for visibility)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Neighborhood', fontsize=12)\n",
    "plt.ylabel('Price (CHF)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/price_distribution_neighborhoods.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"This box plot reveals price ranges and outliers in each neighborhood.\")\n",
    "print(\"Wide boxes indicate diverse price points; narrow boxes suggest homogeneous pricing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Stacked Bar Chart - Room Type Composition by Neighborhood\n",
    "room_type_counts = pd.crosstab(\n",
    "    df_top_neighborhoods['neighbourhood_cleansed'],\n",
    "    df_top_neighborhoods['room_type']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "room_type_counts.plot(kind='bar', stacked=True, figsize=(14, 6), colormap='Set2')\n",
    "plt.title('Room Type Composition Across Neighborhoods', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Neighborhood', fontsize=12)\n",
    "plt.ylabel('Number of Listings', fontsize=12)\n",
    "plt.legend(title='Room Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()    \n",
    "plt.savefig('output/room_type_composition.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"This stacked bar chart shows the absolute count of each room type per neighborhood.\")\n",
    "print(\"Tall stacks indicate high supply; the color distribution shows market segmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Scatter Plot - Price vs. Review Score with Neighborhood Colors\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Sample data for better visualization if dataset is large\n",
    "sample_data = df_top_neighborhoods.sample(min(500, len(df_top_neighborhoods)), random_state=42)\n",
    "sample_data = sample_data[sample_data['price'] <= sample_data['price'].quantile(0.95)]\n",
    "\n",
    "neighborhoods = sample_data['neighbourhood_cleansed'].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(neighborhoods)))\n",
    "\n",
    "for idx, neighborhood in enumerate(neighborhoods):\n",
    "    data = sample_data[sample_data['neighbourhood_cleansed'] == neighborhood]\n",
    "    plt.scatter(data['review_scores_rating'], data['price'], \n",
    "                alpha=0.6, s=50, label=neighborhood, color=colors[idx])\n",
    "\n",
    "plt.xlabel('Review Score Rating', fontsize=12)\n",
    "plt.ylabel('Price (CHF)', fontsize=12)\n",
    "plt.title('Relationship Between Price and Review Scores by Neighborhood', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/price_vs_review_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"This scatter plot explores whether higher-priced listings receive better reviews.\")\n",
    "print(\"Clustering patterns reveal neighborhood-specific price-quality relationships.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Histogram - Distribution of Accommodates Capacity\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Overall distribution\n",
    "axes[0].hist(df_clean['accommodates'], bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0].set_xlabel('Number of Guests Accommodated', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Overall Distribution of Property Capacity in Zurich', fontsize=13, fontweight='bold')\n",
    "axes[0].axvline(df_clean['accommodates'].median(), color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Median: {df_clean[\"accommodates\"].median()}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# By room type\n",
    "for room_type in df_clean['room_type'].unique():\n",
    "    data = df_clean[df_clean['room_type'] == room_type]['accommodates']\n",
    "    axes[1].hist(data, bins=20, alpha=0.5, label=room_type, edgecolor='black')\n",
    "\n",
    "axes[1].set_xlabel('Number of Guests Accommodated', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Property Capacity Distribution by Room Type', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/capacity_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"These histograms show the distribution of property sizes in Zurich.\")\n",
    "print(\"Most listings accommodate 2-4 guests, indicating a market geared toward couples and small families.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: Heatmap - Correlation Between Review Scores and Other Features\n",
    "# Select relevant numerical columns for correlation analysis\n",
    "correlation_cols = ['price', 'accommodates', 'bedrooms', 'beds', 'bathrooms_clean',\n",
    "                    'number_of_reviews', 'review_scores_rating', \n",
    "                    'review_scores_cleanliness', 'review_scores_location',\n",
    "                    'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "# Create correlation matrix\n",
    "correlation_matrix = df_clean[correlation_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap: Property Features and Review Metrics', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"This heatmap reveals relationships between property features and guest satisfaction.\")\n",
    "print(\"Strong correlations between review dimensions suggest consistent guest experiences.\")\n",
    "print(\"Weak correlation between price and ratings indicates value isn't solely price-dependent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Summary\n",
    "\n",
    "**Our Visualization Choices and Insights:**\n",
    "\n",
    "We created five distinct visualization types to explore different facets of Zurich's Airbnb market, each chosen to reveal specific patterns:\n",
    "\n",
    "**Box Plot (Price Distribution):** The box plots reveal significant price heterogeneity. Median prices cluster around 120-150 CHF across neighborhoods, but Rathaus and Seefeld show notably higher upper quartiles (~220-250 CHF). Outliers reaching 500+ CHF appear in multiple neighborhoods, indicating luxury properties exist even in 'budget' areas. The box width variation  confirms our earlier finding—Enge has enormous spread (high std dev), while Sihlfeld and Alt-Wiedikon show tighter distributions.\n",
    "\n",
    "**Stacked Bar Chart (Room Type Composition):** Langstrasse leads with ~189 total listings, followed by Sihlfeld (~167) and Altstetten (~166). The color distribution is telling: Entire home/apt (teal) comprises roughly 60-80% of inventory across most neighborhoods, with Seefeld showing the highest proportion (~86%). Private rooms (yellow) make up most of the remainder (15-35%), while hotel rooms (purple) and shared rooms (gray) are negligible. This composition suggests Zurich's Airbnb market caters primarily to travelers seeking privacy and autonomy rather than budget hostel-style stays.\n",
    "\n",
    "**Scatter Plot (Price vs. Reviews):** The scatter plot reveals a STRIKING pattern: the overwhelming majority of listings cluster tightly at 4.5-5.0 ratings, creating a dense vertical band on the right side \n",
    "of the plot. This clustering is so extreme that only a handful of listings fall below 4.0 stars—Zurich's Airbnb market demonstrates remarkably consistent quality across all price points. Crucially, no clear relationship emerges between price and ratings: both budget (50-100 CHF) and luxury (400-500 CHF) properties achieve similar 4.5-5.0 ratings, confirming that higher prices don't guarantee better reviews. The neighborhood coloring shows all areas span similar rating ranges, though premium neighborhoods (Rathaus, Seefeld) have more listings in the upper price tiers.\n",
    "\n",
    "**Histogram (Guest Capacity):** The room type breakdown reveals interesting segmentation: Entire home/apt (teal) dominates the 2-4 guest capacity range, with a strong showing at 2 guests (likely studios/-bedrooms). Private rooms (yellow) concentrate at 1-2 guests, serving solo travelers and couples seeking budget options. Very few shared rooms or hotel rooms exist in the dataset, indicating Zurich's hort-term rental market primarily serves travelers seeking private spaces rather than hostel-style accommodations. Properties accommodating 6+ guests are almost exclusively entire homes, suggesting families and groups need dedicated rentals rather than private rooms.\n",
    "\n",
    "**Correlation Heatmap:** The correlation heatmap quantifies the relationships we've observed. Property size features show moderate-to-strong correlations: accommodates-beds (0.65), bedrooms-beds \n",
    "(0.67), and bedrooms-accommodates (0.43). The `bathrooms_clean` variable correlates moderately with size (0.27-0.33), confirming that larger properties typically have more bathrooms. Most striking is the review score cluster—all review dimensions correlate strongly with each other (0.39-0.60), with the tightest relationship between overall rating and value (0.60). This suggests hosts who excel in one area typically excel across the board. Critically, price shows near-zero correlation with review scores (0.02 with ratings, -0.00 with value), confirming our scatter plot observation: quality is independent of price in Zurich's market. The 0.52 correlation between number_of_reviews and reviews_per_month indicates established listings (more total reviews) maintain steady booking velocity.\n",
    "\n",
    "Together, these visualizations paint a comprehensive picture of Zurich's short-term rental landscape, moving from geographic patterns to pricing dynamics to quality metrics. Each visualization type was specifically selected to match the nature of the data being explored—categorical comparisons, continuous distributions, relationships, and multidimensional correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Geographic Mapping\n",
    "\n",
    "### Interactive Map of Zurich Airbnb Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base map centered on Zurich\n",
    "zurich_center = [df_clean['latitude'].mean(), df_clean['longitude'].mean()]\n",
    "m = folium.Map(location=zurich_center, zoom_start=12, tiles='OpenStreetMap')\n",
    "\n",
    "# Sample data for performance (plotting all 2500+ points can be slow)\n",
    "map_sample = df_clean.sample(min(1000, len(df_clean)), random_state=42)\n",
    "\n",
    "# Define color scheme based on room type\n",
    "def get_color(room_type):\n",
    "    color_map = {\n",
    "        'Entire home/apt': 'blue',\n",
    "        'Private room': 'green',\n",
    "        'Shared room': 'orange',\n",
    "        'Hotel room': 'red'\n",
    "    }\n",
    "    return color_map.get(room_type, 'gray')\n",
    "\n",
    "# Add markers for each listing\n",
    "for idx, row in map_sample.iterrows():\n",
    "    popup_text = f\"\"\"\n",
    "    <b>{row['name'][:50]}...</b><br>\n",
    "    Neighborhood: {row['neighbourhood_cleansed']}<br>\n",
    "    Room Type: {row['room_type']}<br>\n",
    "    Price: {row['price']} CHF<br>\n",
    "    Accommodates: {row['accommodates']} guests<br>\n",
    "    Rating: {row['review_scores_rating']}\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=3,\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        color=get_color(row['room_type']),\n",
    "        fill=True,\n",
    "        fillOpacity=0.6\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            top: 10px; right: 10px; width: 180px; height: 140px; \n",
    "            background-color: white; border:2px solid grey; z-index:9999; \n",
    "            font-size:14px; padding: 10px\">\n",
    "<p><b>Room Type Legend</b></p>\n",
    "<p><span style=\"color: blue;\">●</span> Entire home/apt</p>\n",
    "<p><span style=\"color: green;\">●</span> Private room</p>\n",
    "<p><span style=\"color: orange;\">●</span> Shared room</p>\n",
    "<p><span style=\"color: red;\">●</span> Hotel room</p>\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Save map\n",
    "m.save('output/zurich_airbnb_map.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap version showing listing density\n",
    "heat_map = folium.Map(location=zurich_center, zoom_start=12, tiles='OpenStreetMap')\n",
    "\n",
    "# Prepare data for heatmap (latitude, longitude, weight)\n",
    "heat_data = [[row['latitude'], row['longitude']] for idx, row in map_sample.iterrows()]\n",
    "\n",
    "# Add heatmap layer\n",
    "HeatMap(heat_data, radius=15, blur=25, max_zoom=13).add_to(heat_map)\n",
    "\n",
    "heat_map.save('output/zurich_airbnb_heatmap.html')\n",
    "print(\"\\nHeatmap shows listing density - darker areas have more rentals.\\n\")\n",
    "\n",
    "heat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Insights\n",
    "\n",
    "**Key Features Revealed by Our Maps:**\n",
    "\n",
    "The geographic visualization of Zurich's Airbnb listings reveals several striking patterns about the city's short-term rental market:\n",
    "\n",
    "**Central Urban Concentration:** The heatmap reveals intense clustering in Zurich's city center and western districts, with the brightest hotspots in the Old Town (Altstadt), Langstrasse, and Industriequartier areas. Rather than forming a single dense core, the market shows 2-3 distinct density centers, reflecting Zurich's polycentric urban structure. The primary concentration occupies the area between Hauptbahnhof (main train station) and the western shore of Lake Zurich, where tourists prioritize proximity to attractions, restaurants, and nightlife.\n",
    "\n",
    "**Lake Zurich Context:** While Lake Zurich dominates the eastern portion of the map, the waterfront itself doesn't show a distinct premium concentration pattern. Listings cluster more heavily in the urban core west of the lake rather than along the shores. This suggests that in Zurich's compact geography, central accessibility matters more than scenic lake views—though lakefront properties certainly exist, they don't drive the overall distribution pattern.\n",
    "\n",
    "**Room Type Distribution - Visual Confirmation:** The point map dramatically illustrates market composition—blue dots (Entire home/apt) outnumber green dots (Private rooms) by approximately 3-4:1 across the city. Blue dots dominate the city center almost completely, while green dots (private rooms) appear more frequently in peripheral neighborhoods like Höngg, Affoltern, and Altstetten. This spatial segregation confirms that budget-conscious travelers seeking private rooms must look to outer districts, while the city center caters primarily to those wanting entire apartments. The near-absence of orange (shared rooms) or red (hotel rooms) confirms Zurich's market serves privacy-seeking travelers, not hostel-style accommodations.\n",
    "\n",
    "**Urban Coverage Pattern:** The listing distribution closely mirrors Zurich's developed urban footprint, extending north to Oerlikon, west to Altstetten, and south to Wollishofen. Density drops sharply beyond the tram and S-Bahn network boundaries, reinforcing that listings cluster where public transportation enables easy city access. The green spaces visible on the map (parks, forests, mountains) naturally contain no listings, creating clear boundaries between rental zones and recreational areas.\n",
    "\n",
    "**Transportation Corridors:** When examined closely, listing density follows Zurich's public transportation network. Areas well-served by trams and S-Bahn trains show higher concentrations, enabling tourists in outlying neighborhoods to access central attractions easily. This correlation makes Zurich particularly accessible—travelers can find affordable options in neighborhoods like Altstetten or Oerlikon while maintaining quick transit connections to the city center.\n",
    "\n",
    "**Strategic Gaps and Regulatory Zones:** Several developed areas show notably sparse listings. The northeastern suburbs (Dübendorf, Wallisellen, parts of Schwamendingen) have limited penetration despite urban development—potentially reflecting stricter short-term rental regulations or lower tourist appeal. Similarly, some affluent southern lakefront areas (Kilchberg, Rüschlikon) show lower density, suggesting  healthier residential zones where property owners prefer long-term stability over rental income. These gaps indicate either regulatory boundaries or neighborhood preferences against short-term tourism, creating de facto \"Airbnb-free zones\" within greater Zurich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Word Cloud Analysis\n",
    "\n",
    "### Analyzing Neighborhood Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all neighborhood overview text\n",
    "# Remove NaN values and concatenate all text\n",
    "all_text = ' '.join(df_clean['neighborhood_overview'].dropna().astype(str))\n",
    "\n",
    "# Basic text cleaning\n",
    "# Remove HTML tags\n",
    "all_text = re.sub(r'<.*?>', '', all_text)\n",
    "# Remove URLs\n",
    "all_text = re.sub(r'http\\S+|www\\S+', '', all_text)\n",
    "# Remove special characters but keep spaces\n",
    "all_text = re.sub(r'[^a-zA-Z\\s]', '', all_text)\n",
    "\n",
    "print(f\"Total text length: {len(all_text)} characters\")\n",
    "print(f\"First 500 characters:\\n{all_text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word cloud\n",
    "# Define common stopwords (including some German words common in Zurich)\n",
    "stopwords = set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
    "                 'of', 'with', 'is', 'are', 'was', 'were', 'been', 'be', 'have', 'has',\n",
    "                 'br', 'b', 'it', 'this', 'that', 'from', 'as', 'by', 'can', 'will',\n",
    "                 'der', 'die', 'das', 'und', 'ist', 'ein', 'eine', 'zu', 'den', 'dem'])\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=1600, height=800,\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,\n",
    "                      min_font_size=10,\n",
    "                      colormap='viridis',\n",
    "                      relative_scaling=0.5,\n",
    "                      max_words=100).generate(all_text)\n",
    "\n",
    "# Display word cloud\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud: Neighborhood Overviews in Zurich Airbnb Listings',\n",
    "          fontsize=18, fontweight='bold', pad=20)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig('output/word_cloud.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display top keywords\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize and count words\n",
    "words = all_text.lower().split()\n",
    "words = [w for w in words if w not in stopwords and len(w) > 3]\n",
    "word_freq = Counter(words)\n",
    "\n",
    "print(\"\\nTop 30 Most Frequent Terms in Neighborhood Descriptions\")\n",
    "print(\"\\nRank | Word | Frequency\")\n",
    "\n",
    "for idx, (word, count) in enumerate(word_freq.most_common(30), 1):\n",
    "    print(f\"{idx:3d}  | {word:20s} | {count:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud Analysis Findings\n",
    "\n",
    "**Emphasized Terms and Their Significance:**\n",
    "\n",
    "The word cloud generated from neighborhood overviews reveals the key selling points that Zurich hosts emphasize when describing their areas:\n",
    "\n",
    "**Location and Accessibility Dominate the Discourse (Top 15 Words):**\n",
    "\n",
    "The most frequent terms overwhelmingly emphasize proximity and connectivity:\n",
    "\n",
    "- **\"Zurich\" (630 occurrences)** and **\"Zürich\" (368)** appear constantly as hosts orient travelers to the city\n",
    "- **\"Restaurants\" (589)** is the #2 most frequent word—hosts aggressively market dining options\n",
    "- **\"City\" (423)** and **\"minutes\" (420)** appear together constantly in phrases like \"5 minutes from city center\"\n",
    "- **\"Tram\" (336)**, **\"walk\" (320)**, **\"station\" (309)**, and **\"train\" (266)** form a transportation vocabulary cluster, appearing in nearly every listing\n",
    "- **\"Lake\" (309)** ranks 11th—Lake Zurich is a consistent selling point even for properties not directly on the water\n",
    "- **\"Close\" (233)**, **\"within\" (231)**, **\"away\" (229)**, and **\"distance\" (189)** create a semantic field of proximity marketing\n",
    "\n",
    "This vocabulary cluster reveals that **walkability and transit access are THE primary value propositions** for Zurich Airbnb hosts. Nearly every description follows the formula: \"Located [X] minutes walk/tram from [attraction].\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Amenities and Lifestyle - The Social Experience:**\n",
    "\n",
    "Beyond transportation, hosts emphasize urban lifestyle amenities:\n",
    "\n",
    "- **\"Restaurants\" (589)** + **\"Bars\" (287)** + **\"Shopping\" (249)** + **\"Shops\" (235)** paint a picture of vibrant neighborhood life\n",
    "- **\"Cafés\"** appears smaller but still prominent, targeting a specific traveler seeking European café culture\n",
    "- **\"Supermarket\"** is visible, addressing practical concerns about groceries \n",
    "- The visual prominence of **\"you\"** (bright yellow, large font) indicates hosts use second-person narrative extensively—\"you can walk,\" \"you will find,\" \"you can enjoy\"\n",
    "\n",
    "**Neighborhood Character - The Dual Promise:**\n",
    "\n",
    "Hosts attempt to balance two potentially contradictory appeals:\n",
    "\n",
    "- **\"Quiet\" (177)** appears frequently, suggesting many travelers seek peaceful retreats\n",
    "- **\"Vibrant,\" \"lively,\"** and **\"trendy\"** also appear, targeting those seeking energy\n",
    "- **\"Neighborhood\" (314)** itself ranks 10th, with hosts emphasizing distinct local character rather than generic urban amenities\n",
    "- **\"Traditional\"** and **\"Swiss\"** appear, marketing authentic local experience\n",
    "- **\"Beautiful\"** is prominently visible, appealing to aesthetic expectations\n",
    "\n",
    "**Geographic Specificity:**\n",
    "\n",
    "Unlike generic descriptions, Zurich hosts frequently name-drop specific locations:\n",
    "- **\"Wiedikon\" (185)** appears in the top 30, indicating hosts in this neighborhood heavily emphasize its name recognition\n",
    "- **\"Langstrasse\"** and **\"Seefeld\"** are both visible in the cloud\n",
    "- **\"Bahnhofstrasse\"** (Zurich's famous shopping street) appears\n",
    "- **\"Old town\"** is mentioned, likely referring to Altstadt\n",
    "\n",
    "This geographic specificity suggests sophisticated marketing—hosts understand that certain neighborhood names carry cachet with informed travelers.\n",
    "\n",
    "**Quantified Convenience - The \"Minutes Walk\" Formula:**\n",
    "\n",
    "The frequency of measurement terms reveals a standardized marketing language:\n",
    "\n",
    "- **\"Minutes\" (420)** + **\"walk/walking\" (320+222)** + **\"distance\" (189)** appear constantly together\n",
    "- This creates formulaic descriptions: \"5 minutes walk to lake,\" \"10 minutes to city center\"\n",
    "- The emphasis on precise walking times suggests travelers prioritize specific, verifiable proximity claims over vague \"nearby\" statements\n",
    "\n",
    "**Missing or Underemphasized Terms:**\n",
    "\n",
    "Interestingly, certain words are conspicuously absent or small:\n",
    "\n",
    "- **Price/value terms** barely appear—hosts don't compete on affordability in descriptions\n",
    "- **WiFi** is smaller than expected, perhaps assumed as standard\n",
    "- **Parking** is relatively small, reflecting Zurich's car-optional urban culture\n",
    "- **Safety/security** terms are minimal, possibly indicating Zurich's baseline safety \n",
    "  reputation\n",
    "\n",
    "**Bilingual/Swiss Elements:**\n",
    "\n",
    "The presence of both \"Zurich\" and \"Zürich\" (with umlaut) reflects the bilingual nature of Swiss tourism marketing, though English dominates the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "The word cloud essentially maps **the language of Zurich tourism marketing**. Hosts have converged on a common vocabulary emphasizing:\n",
    "\n",
    "1. **Walkable proximity** to transportation, lake, and city center (top priority)\n",
    "2. **Dining and nightlife** as lifestyle amenities (restaurants/bars dominate)\n",
    "3. **Neighborhood character** with named districts adding specificity\n",
    "4. **Quantified convenience** with precise distance claims\n",
    "\n",
    "Notably absent are negative qualifiers or caveats—the text corpus is overwhelmingly promotional. Hosts understand that travelers make decisions based on **location verifiability** (can I walk to the lake in 10 minutes?) and **lifestyle aspirations** (can I enjoy restaurants and cafés nearby?). Understanding these linguistic patterns helps both travelers decode marketing speak and hosts optimize their own descriptions to match market expectations.\n",
    "\n",
    "The prominence of second-person address (\"you\") shows hosts write in an intimate, direct style—not listing features but painting scenarios: \"You'll enjoy...\" rather than \"The apartment has...\" This reflects best practices in experiential marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Prediction - Multiple Linear Regression\n",
    "\n",
    "## 2.1 Building a Price Prediction Model\n",
    "\n",
    "### Objective: Predict listing price based on property characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression\n",
    "# First, let's explore potential predictor variables\n",
    "\n",
    "print(\"Potential Numerical Predictors\")\n",
    "numerical_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(numerical_cols[:20])\n",
    "\n",
    "# Remove rows where price is missing or zero\n",
    "df_regression = df_clean[(df_clean['price'].notna()) & (df_clean['price'] > 0)].copy()\n",
    "print(f\"\\nRows available for regression: {len(df_regression)}\")\n",
    "\n",
    "# Explore price distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original price distribution\n",
    "axes[0].hist(df_regression['price'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Price (CHF)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Original Price Distribution')\n",
    "axes[0].axvline(df_regression['price'].median(), color='red', linestyle='--', \n",
    "                label=f'Median: {df_regression[\"price\"].median():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log-transformed price distribution\n",
    "axes[1].hist(np.log(df_regression['price']), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_xlabel('Log(Price)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Log-Transformed Price Distribution')\n",
    "axes[1].axvline(np.log(df_regression['price']).median(), color='red', linestyle='--', \n",
    "                label=f'Median: {np.log(df_regression[\"price\"]).median():.2f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/price_distribution_histograms.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering and selection\n",
    "# Create dummy variables for categorical predictors\n",
    "\n",
    "# Select candidate predictors\n",
    "# Continuous variables\n",
    "continuous_predictors = [\n",
    "    'accommodates', 'bedrooms', 'beds', 'bathrooms_clean',\n",
    "    'number_of_reviews', 'review_scores_rating',\n",
    "    'review_scores_location', 'review_scores_value',\n",
    "    'availability_365', 'minimum_nights'\n",
    "]\n",
    "\n",
    "# Categorical variables\n",
    "categorical_predictors = ['room_type', 'neighbourhood_cleansed']\n",
    "\n",
    "# Create feature dataframe\n",
    "df_model = df_regression[continuous_predictors + categorical_predictors + ['price']].copy()\n",
    "\n",
    "# Handle any remaining missing values in predictors\n",
    "for col in continuous_predictors:\n",
    "    df_model[col] = df_model[col].fillna(df_model[col].median())\n",
    "\n",
    "print(f\"Starting with {len(df_model)} observations and {len(continuous_predictors)} continuous predictors\")\n",
    "\n",
    "# Check correlations with price\n",
    "print(\"\\nCorrelation with Price\")\n",
    "correlations = df_model[continuous_predictors + ['price']].corr()['price'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "\n",
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations[:-1].plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Correlation with Price')\n",
    "plt.title('Feature Correlations with Price')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/correlation_with_price.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for categorical features\n",
    "# For room_type (small number of categories, keep all)\n",
    "room_type_dummies = pd.get_dummies(df_model['room_type'], prefix='room', drop_first=True)\n",
    "\n",
    "# For neighborhood, keep only top 10 to avoid too many features\n",
    "# Combine less common neighborhoods into 'Other'\n",
    "top_neighborhoods = df_model['neighbourhood_cleansed'].value_counts().head(10).index\n",
    "df_model['neighborhood_grouped'] = df_model['neighbourhood_cleansed'].apply(\n",
    "    lambda x: x if x in top_neighborhoods else 'Other'\n",
    ")\n",
    "neighborhood_dummies = pd.get_dummies(df_model['neighborhood_grouped'], prefix='nbhd', drop_first=True)\n",
    "\n",
    "# Combine all features\n",
    "X = pd.concat([\n",
    "    df_model[continuous_predictors],\n",
    "    room_type_dummies,\n",
    "    neighborhood_dummies\n",
    "], axis=1)\n",
    "\n",
    "y = df_model['price']\n",
    "y_log = np.log(df_model['price'])\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X.shape}\")\n",
    "print(f\"Features included: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity\n",
    "print(\"\\nMulticollinearity Analysis\\n\")\n",
    "\n",
    "# Method 1: Correlation-based check\n",
    "print(\"Step 1: Checking correlations between features...\")\n",
    "correlation_matrix = X.corr().abs()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if correlation_matrix.iloc[i, j] > 0.85:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': correlation_matrix.columns[i],\n",
    "                'Feature2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"\\nHighly correlated feature pairs (>0.85):\")\n",
    "    for pair in high_corr_pairs:\n",
    "        print(f\"  {pair['Feature1']} <-> {pair['Feature2']}: {pair['Correlation']:.3f}\")\n",
    "\n",
    "# Method 2: Try VIF calculation with error handling\n",
    "print(\"\\nStep 2: Attempting VIF calculation...\")\n",
    "\n",
    "# Clean data first\n",
    "X_vif = X.copy()\n",
    "X_vif = X_vif.replace([np.inf, -np.inf], np.nan)\n",
    "X_vif = X_vif.fillna(X_vif.median())\n",
    "\n",
    "# Remove constant columns\n",
    "constant_cols = X_vif.columns[X_vif.std() == 0].tolist()\n",
    "if constant_cols:\n",
    "    print(f\"  Removing constant columns: {constant_cols}\")\n",
    "    X_vif = X_vif.drop(columns=constant_cols)\n",
    "\n",
    "try:\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_vif.columns\n",
    "    vif_values = []\n",
    "    \n",
    "    for i in range(X_vif.shape[1]):\n",
    "        try:\n",
    "            vif = variance_inflation_factor(X_vif.values, i)\n",
    "            if np.isnan(vif) or np.isinf(vif):\n",
    "                vif_values.append(999)  # Large placeholder for problematic features\n",
    "            else:\n",
    "                vif_values.append(vif)\n",
    "        except:\n",
    "            vif_values.append(999)\n",
    "    \n",
    "    vif_data[\"VIF\"] = vif_values\n",
    "    vif_data = vif_data.sort_values('VIF', ascending=False)\n",
    "    \n",
    "    print(\"\\nVIF Results (High VIF >10 indicates multicollinearity):\")\n",
    "    print(vif_data.head(10))\n",
    "    \n",
    "    high_vif_features = vif_data[vif_data['VIF'] > 10]['Feature'].tolist()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  VIF calculation failed: {str(e)}\")\n",
    "    print(\"  Using correlation analysis instead.\")\n",
    "    high_vif_features = []\n",
    "\n",
    "# Decide which features to remove\n",
    "print(\"\\nFeature Selection Decision\")\n",
    "features_to_remove = []\n",
    "\n",
    "# Priority 1: Remove 'beds' if it has issues\n",
    "if 'beds' in X.columns:\n",
    "    if high_corr_pairs and any('beds' in [p['Feature1'], p['Feature2']] for p in high_corr_pairs):\n",
    "        features_to_remove.append('beds')\n",
    "        print(\"Removing 'beds': highly correlated with bedrooms/accommodates\")\n",
    "    elif 'beds' in high_vif_features:\n",
    "        features_to_remove.append('beds')\n",
    "        print(\"Removing 'beds': high VIF detected\")\n",
    "\n",
    "# Remove selected features\n",
    "if features_to_remove:\n",
    "    X = X.drop(columns=features_to_remove)\n",
    "    print(f\"\\nFeatures removed: {features_to_remove}\")\n",
    "    print(f\"Remaining features ({len(X.columns)}): {X.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"No features need to be removed\")\n",
    "    print(f\"All features retained ({len(X.columns)})\")\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=0.3, random_state=42)\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics on log scale\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"\\nModel Performance (Log Scale):\")\n",
    "print(f\"Training R^2: {train_r2:.4f}\")\n",
    "print(f\"Test R^2: {test_r2:.4f}\")\n",
    "print(f\"Training RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_test_pred_original = np.exp(y_test_pred)\n",
    "y_test_original = np.exp(y_test)\n",
    "\n",
    "test_rmse_original = np.sqrt(mean_squared_error(y_test_original, y_test_pred_original))\n",
    "test_mae_original = mean_absolute_error(y_test_original, y_test_pred_original)\n",
    "\n",
    "print(f\"\\nModel Performance (Original Scale - CHF):\")\n",
    "\n",
    "print(f\"Test RMSE: CHF {test_rmse_original:.2f}\")\n",
    "print(f\"Test MAE: CHF {test_mae_original:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display regression coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_,\n",
    "    'Percent_Change': (np.exp(model.coef_) - 1) * 100\n",
    "}).sort_values('Percent_Change', ascending=False)\n",
    "\n",
    "\n",
    "print(\"REGRESSION COEFFICIENTS (Sorted by Impact)\")\n",
    "\n",
    "print(f\"Intercept (log scale): {model.intercept_:.4f}\")\n",
    "print(f\"Intercept (original scale): CHF {np.exp(model.intercept_):.2f}\")\n",
    "\n",
    "print(\"\\nTop 10 Positive Drivers:\")\n",
    "print(coefficients.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 10 Negative Drivers:\")\n",
    "print(coefficients.tail(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize actual vs predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Log scale\n",
    "axes[0].scatter(y_test, y_test_pred, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Log(Price)', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted Log(Price)', fontsize=11)\n",
    "axes[0].set_title(f'Actual vs Predicted (Log Scale)\\nR^2 = {test_r2:.3f}', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Original scale\n",
    "axes[1].scatter(y_test_original, y_test_pred_original, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "axes[1].plot([0, y_test_original.max()], [0, y_test_original.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Price (CHF)', fontsize=11)\n",
    "axes[1].set_ylabel('Predicted Price (CHF)', fontsize=11)\n",
    "axes[1].set_title(f'Actual vs Predicted (Original Scale)\\nRMSE = CHF {test_rmse_original:.2f}', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim(0, 500)\n",
    "axes[1].set_ylim(0, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/regression_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Analysis Summary\n",
    "\n",
    "**Process Description:**\n",
    "\n",
    "We developed a multiple linear regression model to predict Airbnb rental prices in Zurich. Our feature selection process involved:\n",
    "\n",
    "1. **Initial Feature Set:** Started with 23 variables including property characteristics (accommodates, bedrooms, bathrooms), location (neighborhood dummies), availability, review metrics, and room type.\n",
    "\n",
    "2. **Multicollinearity Check:** Conducted VIF (Variance Inflation Factor) analysis to identify highly correlated predictors. Removed 'beds' variable due to high VIF (>10) with 'bedrooms' and 'accommodates', leaving us with 22 final predictors.\n",
    "\n",
    "3. **Log Transformation:** Applied natural log transformation to the price variable to address right-skewness in the distribution and stabilize variance, which improved model fit and interpretability.\n",
    "\n",
    "4. **Model Evaluation:** Used train-test split (70/30) to assess out-of-sample performance. Evaluated using R^2, RMSE, and residual analysis.\n",
    "\n",
    "**Model Performance:**\n",
    "\n",
    "The model achieved an **R^2 of 0.375**, explaining 37.5% of the variation in log-transformed prices. The model successfully identifies the primary systematic drivers of pricing that hosts and investors can act upon.\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Room Type Dominates:** The biggest price differentiator is room type, with hotel rooms commanding a 94% premium over entire homes, while private rooms take a 34% discount and shared rooms are discounted 45%. This 139 percentage point range shows that privacy and space type are the strongest price factors.\n",
    "\n",
    "2. **Location Matters More Than Expected:** Neighborhood effects are substantial, with top locations showing 35-44% premiums:\n",
    "   - Altstetten: +44% (strongest location effect)\n",
    "   - Rathaus: +38% (historic central area)\n",
    "   - Seefeld: +36% (lakefront premium)\n",
    "   - Langstrasse: +25% (trendy nightlife district)\n",
    "   \n",
    "   These location premiums actually exceed the impact of capacity, making location selection more important than property size.\n",
    "\n",
    "3. **Capacity Still Important:** Each additional guest a property can accommodate increases price by approximately 18%. Converting a 2-person to 4-person property would justify a 36% price increase, making this a practical lever for hosts to optimize revenue.\n",
    "\n",
    "4. **Bathrooms More Valuable Than Bedrooms:** Each additional bathroom adds 14% to price. Surprisingly, bedrooms show essentially zero effect once we control for total capacity (accommodates). This suggests guests care about total capacity and bathrooms, but not how the sleeping space is divided. For renovation decisions, this clearly prioritizes bathroom additions over bedroom splits.\n",
    "\n",
    "5. **Quality Signals Work:** Review scores rating shows an 11% positive effect, indicating that maintaining high guest satisfaction enables hosts to charge premium prices. This provides a measurable ROI for investing in guest experience.\n",
    "\n",
    "6. **The \"Value Score Paradox\":** Properties with higher \"value for money\" review scores actually have 9% lower prices. This makes economic sense: budget-friendly properties are perceived as better value, while premium properties cannot be both expensive and rated as \"great value\" simultaneously. This suggests hosts should choose strategic positioning—compete on quality/luxury OR value, not both.\n",
    "\n",
    "**Model Limitations:**\n",
    "\n",
    "The model performs well for typical properties in the CHF 50-250 range (approximately 80% of listings) but struggles with luxury properties above CHF 400, contributing to the higher RMSE of CHF 376. The 62.5% unexplained variance represents unmeasured factors such as:\n",
    "- Exact street-level location quality\n",
    "- Recent renovations and property condition\n",
    "- Host responsiveness and personality\n",
    "- Seasonal and event-driven demand fluctuations\n",
    "- Photo quality and listing presentation\n",
    "- Property age and market positioning\n",
    "\n",
    "For practical business applications, the model successfully identifies actionable drivers and provides reliable relative comparisons, even if absolute price predictions have notable error margins.\n",
    "\n",
    "**Business Implications:**\n",
    "\n",
    "- **For Hosts:** Location and room type are primary levers. If you can only improve one thing, prioritize neighborhood over adding capacity. Converting private room → entire home justifies immediate 34% price increase.\n",
    "\n",
    "- **For Investors:** Top neighborhoods (Altstetten, Rathaus, Seefeld) command premiums that exceed size effects, suggesting location should be prioritized in acquisition decisions even if it means accepting smaller properties.\n",
    "\n",
    "- **For Renovations:** Bathroom additions (+14%) provide clear ROI, while bedroom additions show minimal incremental value once capacity is controlled for.\n",
    "\n",
    "- **For Airbnb Platform:** Room type creates the largest price variation (139 point spread), suggesting this filter should be most prominent in search UI. Bedroom count is less important than total capacity for pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 K-nn\n",
    "df_knn = df_clean.copy()\n",
    "\n",
    "amenity_to_predict = \"Dishwasher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = amenity_to_predict.lower().replace(\" \", \" \")\n",
    "\n",
    "df_knn['has_amenity'] = (\n",
    "    df_knn['amenities']\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.contains(amenity_to_predict.lower(), na=False)\n",
    ").astype(int)\n",
    "\n",
    "print(df_knn['has_amenity'].value_counts())\n",
    "print(df_knn['has_amenity'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = [\n",
    "    'accommodates',\n",
    "    'bedrooms',\n",
    "    'beds',\n",
    "    'bathrooms_clean',\n",
    "    'number_of_reviews',\n",
    "    'review_scores_rating',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_location',\n",
    "    'price',\n",
    "    'latitude',\n",
    "    'longitude'\n",
    "]\n",
    "\n",
    "knn_features = [c for c in candidate_features if c in df_knn.columns]\n",
    "print(\"Using predictors:\", knn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn_model = df_knn.dropna(subset=knn_features + ['has_amenity']).copy()\n",
    "\n",
    "X = df_knn_model[knn_features]\n",
    "y = df_knn_model['has_amenity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "k_values = list(range(1, 26, 2))  \n",
    "val_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    val_accuracies.append(acc)\n",
    "    print(f\"k={k}: accuracy={acc:.4f}\")\n",
    "\n",
    "best_k = k_values[int(np.argmax(val_accuracies))]\n",
    "print(\"\\nBest k:\", best_k)\n",
    "print(\"Best accuracy:\", max(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = best_knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== k-NN Results (amenity:\", amenity_to_predict, \") ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "majority_class = y_train.mode()[0]\n",
    "baseline_acc = (y_test == majority_class).mean()\n",
    "print(f\"Baseline (always predict {majority_class}) accuracy: {baseline_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the k-nn classifier, I chose Dishwasher as the amenity to predict. In the Zurich Airbnb data, Wi-Fi is almost universal, but dishwasher is pesent in a substantial but not onverwhelming share of listings (0.56:0.44), giving a more balanced classification problem. I created a binary target variable indicating whether the amenity list for each listing contained \"Dishwasher\" and then using other amenities as predictors along with several review scores. I split the data into training and test sets (70/30) using stratified sampling and standardized predictors.\n",
    "\n",
    "I fit a series of k-NN models using odd k values from 1 to 25 on the scaled tarining data and evaluated each model's accuracy. The final k-NN classifier achieved is k = 7 with accuracy of 0.65. The confusion matrix and classification report show that the model performs somewhat better on predicting listings without a dishwasher (class 0) than those with one(class 1), but it still imporves the precision for the minority \"has dishwasher\" class compared with the naive startegy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Decision Tree\n",
    "\n",
    "df_tree = df_clean.copy()\n",
    "\n",
    "df_tree = df_tree[df_tree['host_response_time'].notna()].copy()\n",
    "\n",
    "print(\"Unique host_response_time values:\", df_tree['host_response_time'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_response = LabelEncoder()\n",
    "df_tree['host_response_time_encoded'] = le_response.fit_transform(df_tree['host_response_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_numeric_features = [\n",
    "    'accommodates',\n",
    "    'bedrooms',\n",
    "    'beds',\n",
    "    'bathrooms_clean',\n",
    "    'number_of_reviews',\n",
    "    'review_scores_rating',\n",
    "    'review_scores_cleanliness',\n",
    "    'review_scores_location',\n",
    "    'review_scores_value',\n",
    "    'price',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'reviews_per_month'\n",
    "]\n",
    "\n",
    "tree_numeric_features = [c for c in tree_numeric_features if c in df_tree.columns]\n",
    "print(\"Numeric predictors:\", tree_numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "if 'room_type' in df_tree.columns:\n",
    "    cat_features.append('room_type')\n",
    "if 'neighbourhood_cleansed' in df_tree.columns:\n",
    "    cat_features.append('neighbourhood_cleansed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tree = pd.get_dummies(df_tree[tree_numeric_features + cat_features], drop_first=True)\n",
    "y_tree = df_tree['host_response_time_encoded']\n",
    "\n",
    "print(\"Tree feature matrix shape:\", X_tree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(\n",
    "    X_tree, y_tree,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_tree\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 8, None],\n",
    "    'min_samples_leaf': [1, 5, 10, 20]\n",
    "}\n",
    "\n",
    "base_tree = DecisionTreeClassifier(random_state=699)\n",
    "\n",
    "grid_tree = GridSearchCV(\n",
    "    estimator=base_tree,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_tree.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(\"Best parameters:\", grid_tree.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_tree.best_estimator_\n",
    "y_pred_tree = best_tree.predict(X_test_tree)\n",
    "\n",
    "print(\"\\n=== Decision Tree Results (host_response_time) ===\")\n",
    "print(\"Test accuracy:\", accuracy_score(y_test_tree, y_pred_tree))\n",
    "print(\"\\nClassification report:\\n\",\n",
    "      classification_report(y_test_tree, y_pred_tree, target_names=le_response.classes_))\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_tree, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    best_tree,\n",
    "    feature_names=X_tree.columns,\n",
    "    class_names=le_response.classes_,\n",
    "    filled=True,\n",
    "    max_depth=3  # just for readability\n",
    ")\n",
    "plt.title(\"Decision Tree for host_response_time (truncated to depth 3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model host responsiveness, I teated host_response_time as a multi-class target with five categories. (\"within an hour\", \"within a few hours\", \"within a day\", \"a few days or more\", and \"unknown\"). I used a set of listing and review characteristics as predictors, and a few key categorical features encoded as dummies. After spliting the test sets, I used a grid search with cross-validation to tune the tree's complexity, varying max_depth and min_samples_leaf. This process was aimed to avoid both overfitting and underfitting.\n",
    "\n",
    "The final decision tree achived about 53% accuracy on the test set, which is only modestly better than a naive strategy that always predicts the majority class (\"within an hour\", roughly 48% of the data). The confusion matrix and classification report show that the model is heavily biased toward this majority class and perfrom poorly on rarer categories. While the tree captures some relationship between listing/review features and very fast responses, it has difficulty disstinguishing among the slower response categories, likely due to class imbalance and overlapping feature patterns. This suggests that additional features (more detailed host-level information) or different methods (class-weighted models) might be needed to get a better predictions across all response-time categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_clean.copy()\n",
    "\n",
    "df_cluster = df_cluster[\n",
    "    (df_cluster['price'].notna()) & \n",
    "    (df_cluster['price'] > 0) & \n",
    "    (df_cluster['accommodates'] > 0)\n",
    "].copy()\n",
    "\n",
    "df_cluster['price_per_guest'] = df_cluster['price'] / df_cluster['accommodates']\n",
    "\n",
    "df_cluster['bathrooms_per_bedroom'] = df_cluster['bathrooms_clean'] / df_cluster['bedrooms'].replace(0, np.nan)\n",
    "df_cluster['bathrooms_per_bedroom'] = df_cluster['bathrooms_per_bedroom'].fillna(\n",
    "    df_cluster['bathrooms_per_bedroom'].median()\n",
    ")\n",
    "\n",
    "review_cols_for_quality = [\n",
    "    'review_scores_rating', \n",
    "    'review_scores_location', \n",
    "    'review_scores_value'\n",
    "]\n",
    "df_cluster['review_quality'] = df_cluster[review_cols_for_quality].mean(axis=1)\n",
    "\n",
    "df_cluster['log_reviews'] = np.log1p(df_cluster['number_of_reviews'])\n",
    "\n",
    "cluster_features = [\n",
    "    'price',\n",
    "    'price_per_guest',\n",
    "    'accommodates',\n",
    "    'bedrooms',\n",
    "    'bathrooms_clean',\n",
    "    'bathrooms_per_bedroom',\n",
    "    'review_quality',\n",
    "    'log_reviews',\n",
    "    'minimum_nights',\n",
    "    'availability_365'\n",
    "]\n",
    "\n",
    "# Ensure no missing values remain in these columns\n",
    "for col in cluster_features:\n",
    "    df_cluster[col] = df_cluster[col].fillna(df_cluster[col].median())\n",
    "\n",
    "Cap extreme outliers at 99th percentile\n",
    "for col in cluster_features:\n",
    "    upper = df_cluster[col].quantile(0.99)\n",
    "    df_cluster[col] = df_cluster[col].clip(upper=upper)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_cluster = df_cluster[cluster_features].values\n",
    "X_cluster_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "print(\"Clustering feature matrix shape:\", X_cluster_scaled.shape)\n",
    "print(\"Features used:\", cluster_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "**Cluster Features:**\n",
    "1. Price\n",
    "2. Price per Guest\n",
    "3. Accomodates\n",
    "4. Bedrooms\n",
    "5. Bathrooms Clean\n",
    "6. Bathrooms per Bedroom\n",
    "7. Review Quality\n",
    "8. Log Reviews\n",
    "9. Minimum Nights\n",
    "10. Availability (365)\n",
    "\n",
    "- When looking at the variables that could be chosen for the model building, it was important to identify information that would be important when looking at why there would be more property value and what would indicate specific things about these properties. \n",
    "\n",
    "**Additional Features**\n",
    "- Some of these features were also chosen because when they are put together, they can indicate even more about the property itself. When these are combined it shines more light on the overall prospects of the property and the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = {}\n",
    "\n",
    "k_values = range(2, 9)\n",
    "for k in k_values:\n",
    "    kmeans_tmp = KMeans(\n",
    "        n_clusters=k, \n",
    "        random_state=699,\n",
    "        n_init=20\n",
    "    )\n",
    "    labels_tmp = kmeans_tmp.fit_predict(X_cluster_scaled)\n",
    "    sil = silhouette_score(X_cluster_scaled, labels_tmp)\n",
    "    silhouette_scores[k] = sil\n",
    "    print(f\"k={k}: silhouette score = {sil:.3f}\")\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(silhouette_scores.keys()),\n",
    "         list(silhouette_scores.values()),\n",
    "         marker='o')\n",
    "plt.xlabel('Number of clusters (k)', fontsize=11)\n",
    "plt.ylabel('Silhouette score', fontsize=11)\n",
    "plt.title('Silhouette Scores for K-Means Clustering', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/kmeans_silhouette_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Cluster\n",
    "\n",
    "**How we chose the number of clusters**\n",
    "- When looking at the best K cluster, based on the silhouette score the best cluster would be cluster 3 which has the highest silhouette score, which indicates that there is the strongest mathematical justification. \n",
    "- This can also be noted in the graphic where cluster (k) = 3 has the highest silhouette score, indicating clear and interpretable market data with proper separation seen in other clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=699)\n",
    "components = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "df_cluster['PC1'] = components[:, 0]\n",
    "df_cluster['PC2'] = components[:, 1]\n",
    "\n",
    "print(\"Explained variance ratio by PC1 and PC2:\",\n",
    "      pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plot_sample = df_cluster.sample(\n",
    "    min(1500, len(df_cluster)), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=plot_sample,\n",
    "    x=\"PC1\", y=\"PC2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=\"Set2\",\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.title(\"PCA Projection of Zurich Airbnb Listings by K-Means Cluster (k=3)\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Principal Component 1\", fontsize=12)\n",
    "plt.ylabel(\"Principal Component 2\", fontsize=12)\n",
    "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/kmeans_pca_clusters_k3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (Principal Component Analysis)\n",
    "\n",
    "**PCA Descirption**\n",
    "- The PCA visualizes our Zurich Airbnb listings in two-dimensional PCA spaces, with each point representing one rental unit and each color representing one of the three clusters that were identified above by k-means. This was the optimal number of clusters that was mentioned above and identified as the best with the silhouette score. When looking at the listings they are broken down into the 3 clusters.\n",
    "\n",
    "    - These clusters separate cleanly, and there can be three distinct clouds, that are identified by out feature engineering to include price per guest, size, review quality, availability, ext as identified above.\n",
    "\n",
    "    - PC1 separates listings by size/price, so looking at the left is smaller and cheaper properties, and the right is larger and more expensive.\n",
    "\n",
    "    - PC2 separates listings by quality and booking dynamics, so the low is average quality and demand and high is premium units with strong reviews or high turnover.\n",
    "\n",
    "**Cluster 2 (Blue) - \"High-End\", High-Quality, High-Capacity Listings**\n",
    "- This can be noted as the high points on PC1 and PC2.\n",
    "- There is a large vertical spread compared to the other clusters.\n",
    "- Blue properties differ from the other two clusters.\n",
    "\n",
    "Cluster 2 listings tend to be more expensive, larger (have bigger accommodation and or bedrooms), have better review quality, and have higher booking activity. These could be premium or upscale units and possibly be entire apartments for families or corporate travelers, or groups. Larger properties may have a larger price and be more expensive and will likely carry bigger experiences that could alter the likelihood that they have a good review. This is our premium or upscale units.\n",
    "\n",
    "**Cluster 1 (Orange) - \"Budget\", Compact, Lower-Priced Rentals**\n",
    "- This cluster sits far left on PC1 (This indicates that there are smaller, cheaper, and lower capacity properties)\n",
    "- Moderate PC2 values\n",
    "- Forms a very dense and tight cluster, this shows that these listings are very similar to each other.\n",
    "\n",
    "These listings tend to be lower prices, and smaller, have lower accommodations and bedrooms than Cluster 2, often targeting individuals such as solo travelers or couples, and will be more uniform in their features. This can be seen in their tight clustering with not much differentiation between them from each other. These are our budget and compact stay segments.\n",
    "\n",
    "**Cluster 0 (Green) - \"Mid Range\", Standard apartments**\n",
    "- This cluster dominates the right side of the graph, targeting the lower right.\n",
    "- This is a moderate sized, more dispersed cluster.\n",
    "\n",
    "These are typical, mid-priced Zurich apartments with moderate size, above average reviews, balanced price per guest, but are not luxury like Cluster 2, but not quite budget like Cluster 1. This is the middle of the market for Zurich. This is the most common Airbnb inventory in major cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(\n",
    "    data=df_cluster, \n",
    "    x='cluster', \n",
    "    y='price', \n",
    "    palette='Set2'\n",
    ")\n",
    "plt.title('Price Distribution by Cluster', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Price (CHF)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/cluster_price_boxplot.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot\n",
    "\n",
    "**Boxplot Explanation**\n",
    "- This boxplot shows how nightly prices differ across our three clusters. Like what we saw in our PCA analysis, our Cluster 2 is the highest priced properties. We can see that the average price for cluster 2 is around $550. This is called the High end cluster. The same observations can be had for cluster 1 and 0, because it's partially what fed into the data for the PCA, but delves further into the actual average price of each cluster. Our Cluster 1 \"Budget\" can be seen as having an average price of roughly $100. Our Cluster 0 \"Mid Range\" has an average price of roughly $210. This properly shows each of the clusters breaking out its distinct values within Zurich and organizes the data to represent the key features targeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = df_cluster.groupby('cluster')['accommodates'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(\n",
    "    data=cluster_sizes, \n",
    "    x='cluster', \n",
    "    y='accommodates', \n",
    "    palette='Set2'\n",
    ")\n",
    "plt.title('Average Guest Capacity by Cluster', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Average Number of Guests', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/cluster_accommodates_barplot.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Chart\n",
    "\n",
    "**Bar Chart Explanation**\n",
    "- When looking at the bar chart it compares the average number of guests each cluster can accommodate. **Budget listings (Cluster 1)** host the fewest number of people, While **Mid Range (Cluster 0)** accommodates the most people and more spacious rentals. **High end (Cluster 2)** averages around 3 guests but costs the most and is considered a luxury property and may be more compact listings. The PCA indicates that High end has limited larger properties but remains high in price for the properties that they have showing that they could be nicer in quality and not size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
